{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import larq as lq\n",
    "import numpy as np\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras as keras\n",
    "class Multibin(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, out_channel, kernel_size, M=1, **kwargs):\n",
    "        self.out_channel = out_channel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.M=M\n",
    "        self.kwargs=kwargs\n",
    "        super(Multibin, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "#         super(Multibin, self).build(**kwargs)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.layers=[]\n",
    "        for i in range(self.M):\n",
    "            self.layers.append(lq.layers.QuantConv2D(self.out_channel, \n",
    "                                                  self.kernel_size, \n",
    "                                                  padding=\"same\", \n",
    "                                                  **self.kwargs))\n",
    "        # Be sure to call this at the end\n",
    "    def conv_output_length(input_length, filter_size,\n",
    "                       padding, stride, dilation=1):\n",
    "        \"\"\"Determines output length of a convolution given input length.\n",
    "        # Arguments\n",
    "            input_length: integer.\n",
    "            filter_size: integer.\n",
    "            padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n",
    "            stride: integer.\n",
    "            dilation: dilation rate, integer.\n",
    "        # Returns\n",
    "            The output length (integer).\n",
    "        \"\"\"\n",
    "        if input_length is None:\n",
    "            return None\n",
    "        assert padding in {'same', 'valid', 'full', 'causal'}\n",
    "        dilated_filter_size = (filter_size - 1) * dilation + 1\n",
    "        if padding == 'same':\n",
    "            output_length = input_length\n",
    "        elif padding == 'valid':\n",
    "            output_length = input_length - dilated_filter_size + 1\n",
    "        elif padding == 'causal':\n",
    "            output_length = input_length\n",
    "        elif padding == 'full':\n",
    "            output_length = input_length + dilated_filter_size - 1\n",
    "        return (output_length + stride - 1) // stride\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "        elif self.data_format == 'channels_first':\n",
    "            space = input_shape[2:]\n",
    "        new_space = []\n",
    "        for i in range(len(space)):\n",
    "            new_dim = conv_output_length(\n",
    "                space[i],\n",
    "                self.kernel_size[i],\n",
    "                padding=self.padding,\n",
    "                stride=self.strides[i],\n",
    "                dilation=self.dilation_rate[i])\n",
    "            new_space.append(new_dim)\n",
    "        if self.data_format == 'channels_last':\n",
    "            return (input_shape[0],) + tuple(new_space) + (self.filters,)\n",
    "        elif self.data_format == 'channels_first':\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs=self.layers[0](inputs)\n",
    "        for i in range(1, self.M):\n",
    "            outputs = outputs+self.layers[i](inputs)\n",
    "        return outputs\n",
    "\n",
    "    # def compute_output_shape(self, input_shape):\n",
    "    #   shape = tf.TensorShape(input_shape).as_list()\n",
    "    #   shape[-1] = self.out_channel\n",
    "    #   return tf.TensorShape(shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(Multibin, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "data = np.random.random((1000, 32 , 32, 3))\n",
    "labels = np.random.random((1000, 10))\n",
    "# Create a model using the custom layer\n",
    "inputs = tf.keras.Input(shape=(32,32,3))\n",
    "Multibin1 = Multibin(10,3, name=\"MultiBin_1\")\n",
    "out1 = Multibin1(inputs)\n",
    "out2 = tf.keras.layers.Dense(10)(out1)\n",
    "final = tf.keras.layers.Activation('softmax')(out2)\n",
    "\n",
    "model1=Model(inputs=inputs, outputs=final)\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Multibin1)\n",
    "# model.add(tf.keras.layers.Dense(10, name=\"final_out\"))\n",
    "# model.add(tf.keras.layers.Activation('softmax', name=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_Multibin1 = Multibin(10,3, name=\"MultiBin_1\")\n",
    "model2_out1 = Multibin1(inputs)\n",
    "model2_out2 = tf.keras.layers.Dense(10)(model2_out1)\n",
    "model2_final = tf.keras.layers.Activation('softmax')(model2_out2)\n",
    "model2 = Model(inputs=inputs,outputs=model2_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tealoss=K.sum(out1-model2_out1,axis=[1,2,3]) + K.sum(out2-model2_out1,axis=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_7:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tealoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "('Could not interpret loss function identifier:', <tf.Tensor 'add_7:0' shape=(?,) dtype=float32>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-9d15fa8a54ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n\u001b[0;32m----> 2\u001b[0;31m               loss=[tealoss], metrics=['accuracy'])\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yjm_py3/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yjm_py3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                          \u001b[0;34m'The model has '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                          ' outputs, but you passed loss=' + str(loss))\n\u001b[0;32m--> 280\u001b[0;31m       \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yjm_py3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    278\u001b[0m                          \u001b[0;34m'The model has '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                          ' outputs, but you passed loss=' + str(loss))\n\u001b[0;32m--> 280\u001b[0;31m       \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m       \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yjm_py3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mget_loss_function\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    871\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MSE'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/yjm_py3/lib/python3.6/site-packages/tensorflow/python/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     raise ValueError('Could not interpret '\n\u001b[0;32m--> 601\u001b[0;31m                      'loss function identifier:', identifier)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('Could not interpret loss function identifier:', <tf.Tensor 'add_7:0' shape=(?,) dtype=float32>)"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.001),\n",
    "              loss=[tealoss], metrics=['accuracy'])\n",
    "\n",
    "model.fit(data, [labels, modelB.predict(data)], epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation/truediv:0\", shape=(?, 32, 32, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "a = Input(shape=(32,))\n",
    "b = Dense(32)(a)\n",
    "model = Model(inputs=a, outputs=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_15:0\", shape=(?, 32, 32, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def at(x):\n",
    "    out = F.normalize(x.pow(2).mean(1).view(x.size(0), -1))\n",
    "    # print(\"out is \", out)\n",
    "    return out\n",
    "\n",
    "def at_loss(x, y):\n",
    "    return (at(x) - at(y)).pow(2).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
